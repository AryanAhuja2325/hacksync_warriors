"""
Reasoning Agent - Post-hoc Explainability Wrapper
Generates human-readable explanations for agent outputs without modifying them.
"""

from mistralai import Mistral
import os
from dotenv import load_dotenv
import json
from typing import Dict, Any

load_dotenv()

MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")

EXPLAINABLE_AI_PROMPT = """You are a specialized AI agent in a campaign intelligence system.
Your task is to explain why a generated output is appropriate for the given strategy.

For every decision, recommendation, or generated item, you must:
1. Provide a short, human-readable explanation
2. Reference the input strategy (audience, goal, tone, platform, region, etc.)
3. Be specific (not generic like "this is best practice")
4. Be concise (1-2 sentences maximum)
5. Write for a non-technical user

If you are unsure, say so explicitly rather than guessing.

Output format:
Return ONLY the explanation text. No JSON. No extra formatting.

Never fabricate facts â€” if something is an assumption, say it is an assumption.
"""


def generate_reasoning(
    agent_name: str,
    strategy: Dict[str, Any],
    agent_output: Any
) -> str:
    """
    Generate explanation for why agent output matches the strategy.
    
    Args:
        agent_name: Name of the agent (e.g., "copywriting", "visual", "media")
        strategy: Original strategy/input that was passed to agent
        agent_output: The output generated by the agent
    
    Returns:
        Human-readable explanation (1-2 sentences)
    """
    if not MISTRAL_API_KEY:
        return "Reasoning unavailable (no API key configured)"
    
    try:
        client = Mistral(api_key=MISTRAL_API_KEY)
        
        # Build context message
        context = f"""Agent: {agent_name}

Strategy:
{json.dumps(strategy, indent=2)}

Generated Output:
{json.dumps(agent_output, indent=2)}

Explain in 1-2 sentences why this output is appropriate for this strategy."""
        
        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[
                {"role": "system", "content": EXPLAINABLE_AI_PROMPT},
                {"role": "user", "content": context}
            ],
            temperature=0.3,
            max_tokens=150
        )
        
        explanation = response.choices[0].message.content.strip()
        return explanation
        
    except Exception as e:
        return f"Reasoning failed: {str(e)}"


def wrap_with_reasoning(
    agent_name: str,
    strategy: Dict[str, Any],
    agent_output: Any
) -> Dict[str, Any]:
    """
    Wrap agent output with reasoning explanation.
    
    Args:
        agent_name: Name of the agent
        strategy: Original strategy
        agent_output: Raw output from agent
    
    Returns:
        {"result": agent_output, "reason": explanation}
    """
    reason = generate_reasoning(agent_name, strategy, agent_output)
    
    return {
        "result": agent_output,
        "reason": reason
    }
